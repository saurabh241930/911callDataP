{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_LSTM_text_generation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh241930/MachineLearningPractice/blob/master/Keras_LSTM_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQ18Kd5F3uKe",
        "outputId": "3814d896-b7e7-492d-fff4-8c9ade9f304e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!curl https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt > shakespeare_input.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4466k  100 4466k    0     0  4154k      0  0:00:01  0:00:01 --:--:-- 4154k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZkrNd2eoYc3",
        "colab_type": "code",
        "outputId": "7fbcefd4-b852-4809-f633-b4ecb884c728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "DATA_PATH = 'shakespeare_input.txt'\n",
        "\n",
        "data = open(DATA_PATH, 'r').read()\n",
        "chars = list(set(data)) #set: gets unique values\n",
        "VOCAB_SIZE = len(chars)\n",
        "\n",
        "print('chars:\\n{}\\n\\nVOCAB_SIZE: {}'.format(chars, VOCAB_SIZE))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chars:\n",
            "['A', 'b', 's', 'E', 'T', 'F', 'y', 'U', 'K', '$', ';', '.', 'q', 'C', 'S', 'W', '&', 'l', 'f', 'j', 'n', ',', 'm', '-', 'H', 'k', '\\n', 'P', '[', ' ', ':', 'i', ']', \"'\", 'R', 'N', 'D', 'w', 'o', 'u', 'g', 'p', 'I', 'Y', 'V', '3', 'B', 'O', 'Z', 'h', '!', 'G', 'd', 'Q', 'J', 'X', 'a', '?', 'M', 't', 'c', 'z', 'r', 'v', 'L', 'x', 'e']\n",
            "\n",
            "VOCAB_SIZE: 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWcw543Poox4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_to_char = {i: char for i, char in enumerate(chars)}\n",
        "char_to_idx = {char: i for i, char in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkdDHotLo3ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "SEQ_LENGTH = 60 #input sequence length\n",
        "N_FEATURES = VOCAB_SIZE #one hot encoding here, that's why, but deduplicated for clarity\n",
        "\n",
        "N_SEQ = int(np.floor((len(data) - 1) / SEQ_LENGTH))\n",
        "\n",
        "X = np.zeros((N_SEQ, SEQ_LENGTH, N_FEATURES))\n",
        "y = np.zeros((N_SEQ, SEQ_LENGTH, N_FEATURES))\n",
        "\n",
        "for i in range(N_SEQ):\n",
        "  X_sequence = data[i * SEQ_LENGTH: (i + 1) * SEQ_LENGTH] #retrieving line \n",
        "  X_sequence_ix = [char_to_idx[c] for c in X_sequence] # converting char into index\n",
        "  input_sequence = np.zeros((SEQ_LENGTH, N_FEATURES))\n",
        "  for j in range(SEQ_LENGTH):\n",
        "    input_sequence[j][X_sequence_ix[j]] = 1. #one-hot encoding of the input characters\n",
        "  X[i] = input_sequence\n",
        "  \n",
        "  y_sequence = data[i * SEQ_LENGTH + 1: (i + 1) * SEQ_LENGTH + 1] #shifted by 1 to the right\n",
        "  y_sequence_ix = [char_to_idx[c] for c in y_sequence]\n",
        "  target_sequence = np.zeros((SEQ_LENGTH, N_FEATURES))\n",
        "  for j in range(SEQ_LENGTH):\n",
        "    target_sequence[j][y_sequence_ix[j]] = 1. #one-hot encoding of the target characters\n",
        "  y[i] = target_sequence\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aEkvjVt52aK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06504fdc-0a83-494e-8beb-359729c234ac"
      },
      "source": [
        "X_sequence"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' shock them. Nought shall make us rue,\\nIf England to itself '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX0m4lOFo8I4",
        "colab_type": "code",
        "outputId": "0046b6f9-5a31-43ac-999c-a3f88d9e4778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import CuDNNLSTM, TimeDistributed, Dense, Activation\n",
        "\n",
        "# constant parameter for the model\n",
        "HIDDEN_DIM = 700 #size of each hidden layer, \"each layer has 700 hidden states\"\n",
        "LAYER_NUM = 2 #number of hidden layers, how much were used?\n",
        "NB_EPOCHS = 200 #max number of epochs to train, \"200 epochs\"\n",
        "BATCH_SIZE = 128 \n",
        "VALIDATION_SPLIT = 0.1 #proportion of the batch used for validation at each epoch\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(HIDDEN_DIM, \n",
        "               input_shape=(None, VOCAB_SIZE), \n",
        "               return_sequences=True))\n",
        "for _ in range(LAYER_NUM - 1):\n",
        "  model.add(CuDNNLSTM(HIDDEN_DIM, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4abv-CMpH6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, length):\n",
        "  ix = [np.random.randint(VOCAB_SIZE)]\n",
        "  y_char = [idx_to_char[ix[-1]]]\n",
        "  X = np.zeros((1, length, VOCAB_SIZE))\n",
        "  for i in range(length):\n",
        "    X[0, i, :][ix[-1]] = 1.\n",
        "    ix = np.argmax(model.predict(X[:, :i+1,:])[0], 1)\n",
        "    y_char.append(idx_to_char[ix[-1]])\n",
        "  return ''.join(y_char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL6Pfcm9pM_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "# callback to save the model if better\n",
        "filepath=\"tgt_model.hdf5\"\n",
        "save_model_cb = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "# callback to stop the training if no improvement\n",
        "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=0)\n",
        "# callback to generate text at epoch end\n",
        "class generateText(Callback):\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        print(generate_text(self.model, 100))\n",
        "        \n",
        "generate_text_cb = generateText()\n",
        "\n",
        "callbacks_list = [save_model_cb, early_stopping_cb, generate_text_cb]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZB9Xk0MpPRP",
        "colab_type": "code",
        "outputId": "c303498b-a1c3-460b-fe04-434bf518532a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        }
      },
      "source": [
        "model.fit(X, y, batch_size=BATCH_SIZE, verbose=1, epochs=NB_EPOCHS, callbacks=callbacks_list, validation_split=VALIDATION_SPLIT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 68599 samples, validate on 7623 samples\n",
            "Epoch 1/200\n",
            "68599/68599 [==============================] - 119s 2ms/step - loss: 2.3805 - acc: 0.3334 - val_loss: 1.8252 - val_acc: 0.4591\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45908, saving model to tgt_model.hdf5\n",
            "le shall be the such of the streather the streather the streather the streather the streather the str\n",
            "Epoch 2/200\n",
            "68599/68599 [==============================] - 114s 2ms/step - loss: 1.5987 - acc: 0.5188 - val_loss: 1.5541 - val_acc: 0.5327\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45908 to 0.53269, saving model to tgt_model.hdf5\n",
            " the strength of the reason of the reason\n",
            "That I have seen the state of the rest of the reason\n",
            "That I\n",
            "Epoch 3/200\n",
            "68599/68599 [==============================] - 115s 2ms/step - loss: 1.4167 - acc: 0.5655 - val_loss: 1.4731 - val_acc: 0.5541\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.53269 to 0.55408, saving model to tgt_model.hdf5\n",
            ", and the gods to him,\n",
            "And therefore they are the gods of the world\n",
            "To the devil the time of the worl\n",
            "Epoch 4/200\n",
            "68599/68599 [==============================] - 115s 2ms/step - loss: 1.3388 - acc: 0.5850 - val_loss: 1.4332 - val_acc: 0.5666\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.55408 to 0.56656, saving model to tgt_model.hdf5\n",
            "?\n",
            "\n",
            "PRINCE HENRY:\n",
            "I would have the start of me to the contrary of the state\n",
            "To the state of me to the \n",
            "Epoch 5/200\n",
            "68599/68599 [==============================] - 115s 2ms/step - loss: 1.2897 - acc: 0.5974 - val_loss: 1.4154 - val_acc: 0.5710\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.56656 to 0.57101, saving model to tgt_model.hdf5\n",
            "the world and the world is so far from the court\n",
            "of the world is so better than the world and the wor\n",
            "Epoch 6/200\n",
            "68599/68599 [==============================] - 115s 2ms/step - loss: 1.2518 - acc: 0.6073 - val_loss: 1.4080 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.57101 to 0.57304, saving model to tgt_model.hdf5\n",
            "me the state of the state of the state\n",
            "That had no stronger than the state of mine,\n",
            "That the state of\n",
            "Epoch 7/200\n",
            "68599/68599 [==============================] - 115s 2ms/step - loss: 1.2184 - acc: 0.6164 - val_loss: 1.4045 - val_acc: 0.5745\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.57304 to 0.57455, saving model to tgt_model.hdf5\n",
            "quarrel to the court,\n",
            "And there are made of them at the state of heart\n",
            "That he hath sent to be a barr\n",
            "Epoch 8/200\n",
            "68599/68599 [==============================] - 115s 2ms/step - loss: 1.1873 - acc: 0.6252 - val_loss: 1.4156 - val_acc: 0.5744\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.57455\n",
            "d the sea that have so long a trifle to the state,\n",
            "To the supposed for the state of thine own service\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe6558ed68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}